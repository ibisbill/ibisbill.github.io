<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Publications - Maggie Huan</title>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&family=Playfair+Display:ital,wght@0,600;1,600;1,700&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="components/style.css">
</head>
<body>

    <nav>
        <div class="container nav-inner">
            <div class="nav-logo">Maggie Ziyu Huan</div>
            <div class="nav-links">
                <a href="index.html">About</a>
                <a href="publications.html" class="active">Publications</a>
                <a href="data/llm_guide_site/index.html">Study Guide</a>
            </div>
        </div>
    </nav>

    <div class="container">
        <header style="padding: 60px 0 40px;">
            <h1 style="font-size: 3rem; margin-bottom: 0.5rem;">Publications</h1>
            <p style="font-size: 1.25rem; color: var(--text-muted); font-family: var(--sans);">Papers, Preprints, and Scholarly Work</p>
        </header>

        <section>
            <div class="section-title">2025</div>
            
            <div class="pub-list">
                
                <div class="pub-item highlight">
                    <div class="pub-content">
                        <div class="pub-title">World Models with Hints of Large Language Models for Goal Achieving</div>
                        <div class="pub-authors">
                            Zeyuan Liu*, <strong>Maggie Huan*</strong>, Xiyao Wang, Jiafei Lyu, Jian Tao, Xiu Li†, Furong Huang†, Huazhe Xu†
                        </div>
                        <div class="pub-venue">
                            NAACL 2025 <span class="tag-oral">Oral</span>
                        </div>
                        <div class="pub-links">
                            <a href="https://aclanthology.org/2025.naacl-long.3/" target="_blank">Paper</a>
                            <a href="https://github.com/ibisbill/DLLM" target="_blank">Code</a>
                        </div>
                    </div>
                </div>

                <div class="pub-item">
                    <div class="pub-content">
                        <div class="pub-title">A Dataset for Distilling Knowledge Priors from Literature for Scientific Discovery</div>
                        <div class="pub-authors">
                            Haydn Jones, Natalie Maus, Josh Ludan, <strong>Maggie Huan</strong>, Jiaming Liang, Marcelo Der Torossian Torres, Zachary Ives, Yoseph Barash, Cesar de la Fuente-Nunez, Jiatao Liang, Jacob R. Gardner, Mark Yatskar
                        </div>
                        <div class="pub-venue">NeurIPS 2025</div>
                        <div class="pub-links">
                            <a href="https://arxiv.org/abs/2508.10899" target="_blank">Paper</a>
                            <a href="https://huggingface.co/DocAndDesign" target="_blank">Huggingface</a>
                        </div>
                    </div>
                </div>

            </div>
        </section>

        <section>
            <div class="section-title">Preprints</div>

            <div class="pub-list">
                <div class="pub-item highlight">
                    <div class="pub-content">
                        <div class="pub-title">Does Math Reasoning Improve General LLM Capabilities? Understanding Transferability of LLM Reasoning</div>
                        <div class="pub-authors">
                            <strong>Maggie Huan*</strong>, Yuetai Li*, Tuney Zheng*, Xiaoyu Xu, Seungone Kim, Minxin Du, Radha Poovendran, Graham Neubig, Xiang Yue
                        </div>
                        <div class="pub-venue">In Submission, 2025</div>
                        <div class="pub-links">
                            <a href="https://arxiv.org/abs/2507.00432" target="_blank">Paper</a>
                            <a href="https://github.com/ReasoningTransfer/Transferability-of-LLM-Reasoning" target="_blank">Code</a>
                            <a href="https://huggingface.co/ReasoningTransferability" target="_blank">Huggingface</a>
                        </div>
                    </div>
                </div>

                <div class="pub-item">
                    <div class="pub-content">
                        <div class="pub-title">Domain Gating Ensemble Networks for AI-Generated Text Detection</div>
                        <div class="pub-authors">
                            Arihant Tripathi, Liam Dugan, Charis Gao, <strong>Maggie Huan</strong>, Meiqing Jin, Peter Zhang, Lyuxin David Zhang, Julia Zhao, Chris Callison-Burch
                        </div>
                        <div class="pub-venue">In Submission, 2025</div>
                        <div class="pub-links">
                            <a href="https://arxiv.org/abs/2505.13855" target="_blank">Paper</a>
                            <a href="https://github.com/Siris2314/dogen" target="_blank">Code</a>
                        </div>
                    </div>
                </div>

                <div class="pub-item">
                    <div class="pub-content">
                        <div class="pub-title">How and Why LLMs Generalize: A Fine-Grained Analysis of LLM Reasoning from Cognitive Behaviors to Low-Level Patterns</div>
                        <div class="pub-authors">
                            Haoyue Bai, Yiyou Sun, Wenjie Hu, Qiu Shi, <strong>Maggie Huan</strong>, Peiyang Song, Robert Nowak, Dawn Song
                        </div>
                        <div class="pub-venue">In Submission, 2025</div>
                        <div class="pub-links">
                            <a href="https://arxiv.org/html/2512.24063v1" target="_blank">Paper</a>
                        </div>
                    </div>
                </div>
            </div>
        </section>
    </div>

    <footer>
        <div class="container">
            <p>&copy; 2026 Maggie Ziyu Huan</p>
        </div>
    </footer>

</body>
</html>