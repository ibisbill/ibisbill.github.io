<!doctype html>
<html lang="zh-Hans">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>7.1 对齐的目标与约束（Helpful/Harmless/Honest）｜Transformer × LLM 学习站</title>
  <link href="https://fonts.googleapis.com/css2?family=JetBrains+Mono:wght@400;500&display=swap" rel="stylesheet">
  <link rel="stylesheet" href="./assets/site.css" />
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@11.9.0/styles/vs2015.min.css" />
  <script>
    window.MathJax = {
      tex: {
        inlineMath: [['$','$'], ['\\(','\\)']],
        displayMath: [['$$','$$'], ['\\[','\\]']],
      },
      options: { skipHtmlTags: ['script','noscript','style','textarea','pre','code'] }
    };
  </script>
  <script defer src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/highlight.js@11.9.0/lib/highlight.min.js"></script>
  <script defer src="./assets/site.js"></script>
  <script>
    document.addEventListener('DOMContentLoaded', () => {
      if (window.hljs) window.hljs.highlightAll();
    });
  </script>
</head>
<body>
  <div class="topbar">
    <div class="container topbar-inner">
      <div class="brand">
        <div class="brand-badge"></div>
        <div>
          <div>Transformer × LLM 学习站</div>
          <div class="brand-sub">知识点 7.1</div>
        </div>
      </div>
      <div class="navlinks">
        <a href="./index.html" class="">目录</a>
        <a href="./module-02-transformer.html" class="">Transformer</a>
        <a href="./module-07-alignment.html" class="active">对齐</a>
        <a href="./module-08-inference.html" class="">推理</a>
      </div>
    </div>
  </div>

  <div class="container">
    
<div class="hero">
  <h1>7.1 对齐的目标与约束</h1>
  <p class="muted">探讨如何将模型的行为与人类价值观对齐，遵循“有用、无害、诚实”的核心准则。</p>
  <div class="pillrow">
    <span class="pill">模块 7</span>
    <span class="pill"><a href="./module-07-对齐-alignment-rlhf-dpo-rlvr-等.html">返回模块页</a></span>
  </div>
</div>

<div class="section">
  <h2>核心知识点详细讲解</h2>

  <h3>1. HHH 准则</h3>
  <p>对齐的核心目标是让模型在交互中遵循以下三个核心约束：</p>
  <ul>
    <li><strong>Helpful (有用性):</strong> 模型应该尽可能地帮助用户完成任务，提供清晰、连贯且相关的回答。</li>
    <li><strong>Harmless (无害性):</strong> 模型不应生成仇恨言论、暴力、色情内容，或协助用户进行非法活动。对于危险请求，模型应采取“安全拒答”策略。</li>
    <li><strong>Honest (诚实性):</strong> 模型应提供真实准确的信息。如果模型不确定某个事实，应明确表达不确定性，而不是编造事实（幻觉）。</li>
  </ul>

  <h3>2. 指令层级 (Instruction Hierarchy)</h3>
  <p>在复杂的对话场景中，不同来源的指令可能存在冲突：</p>
  <ul>
    <li><strong>System Prompt (系统提示):</strong> 优先级最高。定义了模型的角色和核心行为准则。</li>
    <li><strong>Developer Pre-prompt (开发者预设):</strong> 针对特定应用场景的约束。</li>
    <li><strong>User Input (用户输入):</strong> 用户的即时指令。如果用户试图诱导模型违反系统提示（如提示词注入），模型应始终遵循系统提示。</li>
  </ul>

  <h3>3. 安全拒答与过度拒答 (Over-refusal)</h3>
  <p>一个关键的权衡点是：模型既要能拒绝真正的有害请求，又不能因为过于敏感而拒绝合理的提问（如拒绝解释什么是“炸弹”的科学原理）。过度的安全对齐会导致模型变得枯燥且难以使用。</p>
</div>

<div class="section">
  <h2>工程要点总结</h2>
  <ul>
    <li><strong>对抗性评测 (Red Teaming):</strong> 模拟黑客或恶意用户，通过各种诱导手段测试模型的安全防线（越狱测试）。</li>
    <li><strong>对齐税 (Alignment Tax):</strong> 过于严格的对齐往往会导致模型在通用智力任务（如推理、编程）上的性能略微下降。优化的目标是尽量减小这种副作用。</li>
    <li><strong>价值观的一致性:</strong> 模型不仅要遵守法律，还要在多文化背景下保持价值中立或符合特定社会的伦理预期。</li>
  </ul>

  <p>例题与答案：</p>
  <div class="qa">
    <div class="q">Q1：什么是 instruction hierarchy？</div>
    <div class="a">A1：这是一种定义不同级别指令优先权的概念。通常系统提示（System Prompt）拥有最高权限，用户输入最低。对齐良好的模型应当能够识别并抵御用户通过输入手段试图篡改系统级安全设置的行为（即防御提示词注入）。</div>
  </div>
  <div class="qa">
    <div class="q">Q2：诚实对齐的一个可操作准则？</div>
    <div class="a">A2：当模型面临它在训练语料中未覆盖或不确定的事实时，应训练它主动说“我不知道”或“根据我目前掌握的信息，我无法确定”，并给出查证建议，而不是试图为了“有用性”而编造一个听起来合理的答案。</div>
  </div>
</div>

    <div class="pager">
      <a href="module-07-对齐-alignment-rlhf-dpo-rlvr-等.html"><strong>7 对齐（Alignment）：RLHF / DPO / RLVR 等</strong></a>
      <a href="kp-7-2-rlhf-三阶段与-ppo-关键点.html"><strong>7.2 RLHF：三阶段与 PPO 关键点</strong></a>
    </div>
    <div class="footer">
      <div>© 2026 Transformer × LLM 学习站</div>
    </div>
  </div>
</body>
</html>