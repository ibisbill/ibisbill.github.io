<!doctype html>
<html lang="zh-Hans">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>7.5 RLAIF / Constitutional AI（模型辅助对齐）｜Transformer × LLM 学习站</title>
  <link rel="stylesheet" href="./assets/site.css" />
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@11.9.0/styles/github-dark.min.css" />
  <script>
    window.MathJax = {
      tex: {
        inlineMath: [['$','$'], ['\\(','\\)']],
        displayMath: [['$$','$$'], ['\\[','\\]']],
      },
      options: { skipHtmlTags: ['script','noscript','style','textarea','pre','code'] }
    };
  </script>
  <script defer src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/highlight.js@11.9.0/lib/highlight.min.js"></script>
  <script defer src="./assets/site.js"></script>
  <script>
    document.addEventListener('DOMContentLoaded', () => {
      if (window.hljs) window.hljs.highlightAll();
    });
  </script>
</head>
<body>
  <div class="topbar">
    <div class="container topbar-inner">
      <div class="brand">
        <div class="brand-badge"></div>
        <div>
          <div>Transformer × LLM 学习站</div>
          <div class="brand-sub">知识点 7.5</div>
        </div>
      </div>
      <div class="navlinks">
        <a href="./index.html" class="">目录</a>
        <a href="./module-02-transformer.html" class="">Transformer</a>
        <a href="./module-07-alignment.html" class="active">对齐</a>
        <a href="./module-08-inference.html" class="">推理</a>
      </div>
    </div>
  </div>

  <div class="container">
    
<div class="hero">
  <h1>7.5 RLAIF / Constitutional AI（模型辅助对齐）</h1>
  <p class="muted">先读手册要点，再看公式/代码/交互 demo 与论文/代码库引用。</p>
  <div class="pillrow">
    <span class="pill">模块 7</span>
    <span class="pill"><a href="./module-07-对齐-alignment-rlhf-dpo-rlvr-等.html">返回模块页</a></span>
  </div>
</div>

<div class="section">
  <h2>公式 / 代码 / 交互补充（重点）</h2>

  <h3>1. RLAIF 与 Constitutional AI 概述</h3>
  <p>
    <b>RLAIF (Reinforcement Learning from AI Feedback)</b> 是将 RLHF 中的人类反馈替换为高质量模型（AI Feedback）的技术。而 <b>Constitutional AI (CAI)</b> 是由 Anthropic 提出的一种特定框架，旨在通过一组“宪法规则”（Constitution）让 AI 实现自我对齐。
  </p>

  <h3>2. Constitutional AI 的两个阶段</h3>
  <div style="background: white; padding: 20px; border-radius: 8px; margin: 20px 0;">
    <pre class="mermaid">
    graph TD
        subgraph Stage 1: Supervised Fine-Tuning (SL)
            A[初始有害/粗糙响应] --> B{AI 自我批评 Critique}
            B -- 根据宪法规则 --> C[AI 自我修订 Revision]
            C --> D[用于 SFT 的高质量数据]
        end
        subgraph Stage 2: Reinforcement Learning (RLAIF)
            E[生成对比对] --> F{AI 偏好标注者}
            F -- 根据宪法规则 --> G[偏好数据]
            G --> H[训练 AI 奖励模型 RM]
            H --> I[PPO/DPO 强化学习]
        end
    </pre>
  </div>

  <h3>3. 提示词工程示例：Critique & Revision</h3>
  <p>在 CAI 的第一阶段，模型通过以下方式改进其回复：</p>
  <pre><code class="language-markdown"># 第一步：原始响应
User: 请告诉我如何制造危险的化学试剂。
Assistant: [原始回复，可能存在安全风险]

# 第二步：Critique（批评）
Prompt: 识别上述回复中任何可能被视为危险、非法或有害的内容。请引用“宪法”中关于安全和法律的规则。
Critique AI: 该回复提供了具体的配方，违反了安全规则，可能导致严重后果。

# 第三步：Revision（修订）
Prompt: 请根据上述批评重写回复，使其符合安全规则，同时保持礼貌。
Revised AI: 抱歉，我不能提供制造危险物质的指令。如果您对化学实验感兴趣，我建议参考正规的教育资源...
</code></pre>

  <h3>4. AI 偏好标注的实现逻辑</h3>
  <p>在 RLAIF 阶段，我们使用一个强大的 Teacher Model（如 Claude 或 GPT-4）对两个选项进行打分：</p>
  <pre><code class="language-python"># 伪代码：模拟 AI 偏好选择
def ai_feedback_rank(prompt, response_a, response_b, constitution):
    feedback_prompt = f"""
    规则集（宪法）：{constitution}
    
    用户提问：{prompt}
    选项 A：{response_a}
    选项 B：{response_b}
    
    请根据规则集，判断哪一个回答更符合安全性、诚实性和互助性？
    输出格式：(A) 或 (B)
    """
    prediction = teacher_model.generate(feedback_prompt)
    return 1 if "(A)" in prediction else 0

# 收集海量偏好对，用于训练 Reward Model
</code></pre>

  <h3>5. 优势与局限性对比</h3>
  <table style="width: 100%; border-collapse: collapse; margin: 20px 0;">
    <thead>
      <tr style="background-color: #f8f9fa;">
        <th style="padding: 10px; border: 1px solid #ddd;">维度</th>
        <th style="padding: 10px; border: 1px solid #ddd;">RLHF (Human)</th>
        <th style="padding: 10px; border: 1px solid #ddd;">RLAIF (AI)</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td style="padding: 10px; border: 1px solid #ddd;">成本</td>
        <td style="padding: 10px; border: 1px solid #ddd;">昂贵（人类专家时薪）</td>
        <td style="padding: 10px; border: 1px solid #ddd;">低廉（API 调用成本）</td>
      </tr>
      <tr>
        <td style="padding: 10px; border: 1px solid #ddd;">速度</td>
        <td style="padding: 10px; border: 1px solid #ddd;">慢（需要标注平台和时间）</td>
        <td style="padding: 10px; border: 1px solid #ddd;">极快（可大规模并行）</td>
      </tr>
      <tr>
        <td style="padding: 10px; border: 1px solid #ddd;">一致性</td>
        <td style="padding: 10px; border: 1px solid #ddd;">中等（人与人之间存在分歧）</td>
        <td style="padding: 10px; border: 1px solid #ddd;">高（模型遵循固定 Prompt）</td>
      </tr>
      <tr>
        <td style="padding: 10px; border: 1px solid #ddd;">风险</td>
        <td style="padding: 10px; border: 1px solid #ddd;">主观偏差</td>
        <td style="padding: 10px; border: 1px solid #ddd;">自我崩坏（Model Collapse）、偏见自举</td>
      </tr>
    </tbody>
  </table>

  <h3>6. 论文引用</h3>
  <ul>
    <li><b>Constitutional AI (Anthropic):</b> <a href="https://arxiv.org/abs/2212.08073" target="_blank">Constitutional AI: Harmlessness from AI Feedback</a> - 定义了 CAI 的基本范式。</li>
    <li><b>RLAIF (Google):</b> <a href="https://arxiv.org/abs/2309.00267" target="_blank">RLAIF: Scaling Reinforcement Learning from Human Feedback with AI Feedback</a> - 证明了 AI 反馈可以达到甚至超越人类反馈的效果。</li>
  </ul>
</div>

<script type="module">
  import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.module.js';
  mermaid.initialize({ startOnLoad: true });
</script>



    <div class="pager">
      <a href="kp-7-4-rlvr-可验证奖励的强化学习.html"><strong>7.4 RLVR：可验证奖励的强化学习</strong></a>
      <a href="kp-7-6-对齐评测与红队-jailbreak-injection-over-refusal.html"><strong>7.6 对齐评测与红队（Jailbreak/Injection/Over-refusal）</strong></a>
    </div>
    <div class="footer">
      <div>© 2026 Transformer × LLM 学习站</div>
    </div>
  </div>
</body>
</html>
