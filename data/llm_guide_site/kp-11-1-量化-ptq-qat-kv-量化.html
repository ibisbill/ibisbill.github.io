<!doctype html>
<html lang="zh-Hans">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>11.1 量化（PTQ/QAT/KV 量化）｜Transformer × LLM 学习站</title>
  <link rel="stylesheet" href="./assets/site.css" />
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@11.9.0/styles/github-dark.min.css" />
  <script>
    window.MathJax = {
      tex: {
        inlineMath: [['$','$'], ['\\(','\\)']],
        displayMath: [['$$','$$'], ['\\[','\\]']],
      },
      options: { skipHtmlTags: ['script','noscript','style','textarea','pre','code'] }
    };
  </script>
  <script defer src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/highlight.js@11.9.0/lib/highlight.min.js"></script>
  <script defer src="./assets/site.js"></script>
  <script>
    document.addEventListener('DOMContentLoaded', () => {
      if (window.hljs) window.hljs.highlightAll();
    });
  </script>
</head>
<body>
  <div class="topbar">
    <div class="container topbar-inner">
      <div class="brand">
        <div class="brand-badge"></div>
        <div>
          <div>Transformer × LLM 学习站</div>
          <div class="brand-sub">知识点 11.1</div>
        </div>
      </div>
      <div class="navlinks">
        <a href="./index.html" class="">目录</a>
        <a href="./module-02-transformer.html" class="">Transformer</a>
        <a href="./module-07-alignment.html" class="">对齐</a>
        <a href="./module-08-inference.html" class="">推理</a>
      </div>
    </div>
  </div>

  <div class="container">
    
<div class="hero">
  <h1>11.1 量化（PTQ/QAT/KV 量化）</h1>
  <p class="muted">先读手册要点，再看公式/代码/交互 demo 与论文/代码库引用。</p>
  <div class="pillrow">
    <span class="pill">模块 11</span>
    <span class="pill"><a href="./module-11-模型压缩与部署.html">返回模块页</a></span>
  </div>
</div>

<div class="section">
  <h2>手册要点 + 例题答案（原文整理）</h2>
  <p>概述：量化通过降低数值精度减少显存与带宽，提升推理吞吐并降低成本，是部署的常见手段。</p>
<p>你需要掌握：</p>
<ul>
<li>PTQ：后训练量化（INT8/INT4，GPTQ/AWQ 等）。</li>
</ul>
<ul>
<li>QAT：量化感知训练，质量更好但成本更高。</li>
</ul>
<ul>
<li>KV 量化：降低 KV cache 精度，特别利于长上下文。</li>
</ul>
<p>工程提示：</p>
<ul>
<li>量化需要校准数据（代表性很重要）。</li>
</ul>
<ul>
<li>对工具/JSON 任务要重点测试：量化可能更易产生格式错误。</li>
</ul>
<p>常见误区：</p>
<ul>
<li>只看困惑度变化不看任务；量化对结构化输出的影响可能更大。</li>
</ul>
<p>例题与答案：</p>
<div class="qa">
<div class="q">Q1：PTQ 与 QAT 的差异？</div>
</div>
<div class="qa">
<div class="a">A1：PTQ 不再训练模型，靠校准直接量化；QAT 在训练中模拟量化误差以适配。</div>
</div>
<div class="qa">
<div class="q">Q2：KV 量化的收益主要体现在哪？</div>
</div>
<div class="qa">
<div class="a">A2：降低长序列与高并发下 KV cache 的显存与带宽成本。</div>
</div>
</div>

<div class="section"><h2>公式 / 代码 / 交互补充（重点）</h2>
<h3>量化：为什么能显著提速/省显存？</h3>
<ul>
  <li><b>权重量化</b>：把权重从 FP16/FP32 压到 INT8/INT4（或更低），减小模型体积与带宽。</li>
  <li><b>激活量化</b>：对推理中间激活做量化（更难），可进一步提速但更敏感。</li>
  <li><b>KV 量化</b>：长上下文推理下收益非常明显（KV cache 往往占大头）。</li>
</ul>

<h3>原论文与代码库</h3>
<ul>
  <li>GPTQ：Frantar et al., 2022 <a href="https://arxiv.org/abs/2210.17323">GPTQ</a></li>
  <li>AWQ：Lin et al., 2023 <a href="https://arxiv.org/abs/2306.00978">AWQ</a></li>
  <li>工程实现：<a href="https://github.com/ggerganov/llama.cpp">ggerganov/llama.cpp</a>、<a href="https://github.com/bitsandbytes-foundation/bitsandbytes">bitsandbytes</a></li>
</ul>
</div>

    <div class="pager">
      <a href="module-11-模型压缩与部署.html"><strong>11 模型压缩与部署</strong></a>
      <a href="kp-11-2-剪枝与稀疏化-结构化-非结构化.html"><strong>11.2 剪枝与稀疏化（结构化/非结构化）</strong></a>
    </div>
    <div class="footer">
      <div>来源：`Transformer_LLM_Study_Guide_CN.pdf`（生成日期 2026-01-18）</div>
      <div><a href="../transformers/Transformer_LLM_Study_Guide_CN.pdf">打开原 PDF</a></div>
    </div>
  </div>
</body>
</html>
