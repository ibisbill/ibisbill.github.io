<!doctype html>
<html lang="zh-Hans">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>3.1 自回归语言建模（Causal LM）｜Transformer × LLM 学习站</title>
  <link rel="stylesheet" href="./assets/site.css" />
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@11.9.0/styles/github-dark.min.css" />
  <script>
    window.MathJax = {
      tex: {
        inlineMath: [['$','$'], ['\\(','\\)']],
        displayMath: [['$$','$$'], ['\\[','\\]']],
      },
      options: { skipHtmlTags: ['script','noscript','style','textarea','pre','code'] }
    };
  </script>
  <script defer src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/highlight.js@11.9.0/lib/highlight.min.js"></script>
  <script defer src="./assets/site.js"></script>
  <script>
    document.addEventListener('DOMContentLoaded', () => {
      if (window.hljs) window.hljs.highlightAll();
    });
  </script>
</head>
<body>
  <div class="topbar">
    <div class="container topbar-inner">
      <div class="brand">
        <div class="brand-badge"></div>
        <div>
          <div>Transformer × LLM 学习站</div>
          <div class="brand-sub">知识点 3.1</div>
        </div>
      </div>
      <div class="navlinks">
        <a href="./index.html" class="">目录</a>
        <a href="./module-02-transformer.html" class="">Transformer</a>
        <a href="./module-07-alignment.html" class="">对齐</a>
        <a href="./module-08-inference.html" class="">推理</a>
      </div>
    </div>
  </div>

  <div class="container">
    
<div class="hero">
  <h1>3.1 自回归语言建模（Causal LM）</h1>
  <p class="muted">探讨大语言模型最主流的预训练目标：基于上文预测下一个 token。</p>
  <div class="pillrow">
    <span class="pill">模块 3</span>
    <span class="pill"><a href="./module-03-语言建模目标与损失.html">返回模块页</a></span>
  </div>
</div>

<div class="section">
  <h2>核心知识点详细讲解</h2>

  <h3>1. 自回归建模 (Causal Language Modeling)</h3>
  <p>自回归建模的目标是根据序列中先前出现的 token 来预测下一个 token。给定一个长度为 $T$ 的 token 序列 $x_{1:T}$，其联合概率可以分解为条件概率的乘积：</p>
  <p>$$p(x_{1:T}) = \prod_{t=1}^T p(x_t | x_1, x_2, \dots, x_{t-1})$$</p>
  <p>在训练过程中，模型被训练去最大化这个联合概率，或者等价地，最小化负对数似然（Negative Log-Likelihood, NLL）：</p>
  <p>$$\mathcal{L} = - \sum_{t=1}^T \log p(x_t | x_{<t})$$</p>

  <h3>2. 损失函数：交叉熵 (Cross Entropy)</h3>
  <p>在每一时间步 $t$，模型输出一个维度等于词表大小 $V$ 的向量（Logits）$z_t$。通过 Softmax 函数将其转化为概率分布：</p>
  <p>$$p(x_t | x_{<t}) = \text{Softmax}(z_t) = \frac{\exp(z_{t, x_t})}{\sum_{j=1}^V \exp(z_{t, j})}$$</p>
  <p>交叉熵损失度量了预测分布与真实分布（One-hot 编码）之间的差异。对于单个 token，$L = -\log p(x_t | x_{<t})$。</p>

  <h3>3. 困惑度 (Perplexity, PPL)</h3>
  <p>困惑度是语言模型最常用的评估指标，它是交叉熵损失的指数形式：</p>
  <p>$$\text{PPL} = \exp(H(p, q)) = \exp\left( - \frac{1}{T} \sum_{t=1}^T \log q(x_t | x_{<t}) \right)$$</p>
  <p>直观上，困惑度代表了模型在每一步预测时，平均“感到困惑”的选择分支数。PPL 越低，模型预测越准。注意：PPL 与分词器（Tokenizer）强相关，不同分词器的模型不能直接通过 PPL 比较。</p>

  <h3>4. 曝光偏差 (Exposure Bias)</h3>
  <ul>
    <li><strong>训练阶段 (Teacher Forcing):</strong> 模型输入的是来自训练集的真实 token（Ground Truth）。</li>
    <li><strong>推理阶段:</strong> 模型输入的是上一时刻自己生成的 token。如果模型在某一步生成错误，这个错误会累积到下一步，导致生成的序列逐渐偏离分布。这就是“曝光偏差”。</li>
  </ul>

  <h3>代码示例：交叉熵损失计算 (PyTorch 风格)</h3>
  <pre><code class="language-python">import torch
import torch.nn as nn
import torch.nn.functional as F

# 假设词表大小 V=10，序列长度 S=5，Batch 大小 B=2
B, S, V = 2, 5, 10
logits = torch.randn(B, S, V) # 模型输出
targets = torch.randint(0, V, (B, S)) # 真实标签 (Next Tokens)

# 在 Causal LM 中，通常需要对 logits 和 targets 进行错位对齐
# 输入位置 t 的输出应该预测 t+1 位置的 target
# shift_logits = logits[:, :-1, :].contiguous()
# shift_labels = targets[:, 1:].contiguous()

# 计算交叉熵
loss_fct = nn.CrossEntropyLoss()
loss = loss_fct(logits.view(-1, V), targets.view(-1))

print(f"Loss: {loss.item()}")
print(f"Perplexity: {torch.exp(loss).item()}")
</code></pre>
</div>

<div class="section">
  <h2>工程要点总结</h2>
  <ul>
    <li><strong>Sequence Packing:</strong> 为了提高 GPU 利用率，通常会将多条短文本拼接成一个长序列（使用 EOS token 分隔），减少 Padding。</li>
    <li><strong>Loss Masking:</strong> 在对话微调（SFT）中，通常只对“助手”的回答部分计算 Loss，而忽略“系统提示”和“用户问题”部分的 Loss。</li>
    <li><strong>数值稳定性:</strong> 计算 Softmax 时减去最大值以防止溢出，或者直接使用 `log_softmax`。</li>
  </ul>

  <p>例题与答案：</p>
  <div class="qa">
    <div class="q">Q1：为什么推理时错误会“滚雪球”？</div>
    <div class="a">A1：推理输入包含模型先前输出，若前面偏离真实分布，后续条件分布也会随之改变，导致误差逐步累积（即曝光偏差）。</div>
  </div>
</div>

    <div class="pager">
      <a href="module-03-语言建模目标与损失.html"><strong>3 语言建模目标与损失</strong></a>
      <a href="kp-3-2-masked-lm-denoising-目标.html"><strong>3.2 Masked LM / Denoising 目标</strong></a>
    </div>
    <div class="footer">
      <div>© 2026 Transformer × LLM 学习站</div>
    </div>
  </div>
</body>
</html>